"use strict";(self.webpackChunkml_notebook=self.webpackChunkml_notebook||[]).push([[7667],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>g});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(a),f=r,g=m["".concat(s,".").concat(f)]||m[f]||u[f]||i;return a?n.createElement(g,o(o({ref:t},p),{},{components:a})):n.createElement(g,o({ref:t},p))}));function g(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=f;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}f.displayName="MDXCreateElement"},30094:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>b,contentTitle:()=>h,default:()=>v,frontMatter:()=>g,metadata:()=>d,toc:()=>S});var n=a(3905),r=Object.defineProperty,i=Object.defineProperties,o=Object.getOwnPropertyDescriptors,l=Object.getOwnPropertySymbols,s=Object.prototype.hasOwnProperty,c=Object.prototype.propertyIsEnumerable,p=(e,t,a)=>t in e?r(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,m=(e,t)=>{for(var a in t||(t={}))s.call(t,a)&&p(e,a,t[a]);if(l)for(var a of l(t))c.call(t,a)&&p(e,a,t[a]);return e},u=(e,t)=>i(e,o(t)),f=(e,t)=>{var a={};for(var n in e)s.call(e,n)&&t.indexOf(n)<0&&(a[n]=e[n]);if(null!=e&&l)for(var n of l(e))t.indexOf(n)<0&&c.call(e,n)&&(a[n]=e[n]);return a};const g={title:"BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation",authors:["visualdust"],tags:["segmentation","light-weight"]},h=void 0,d={permalink:"/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation",editUrl:"https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation.md",source:"@site/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation.md",title:"BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation",description:"BiSeNet\u7684\u76ee\u6807\u662f\u66f4\u5feb\u901f\u7684\u5b9e\u65f6\u8bed\u4e49\u5206\u5272\u3002\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u611f\u53d7\u91ce\u5f88\u96be\u4e24\u5168\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u65f6\u8bed\u4e49\u5206\u5272\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u662f\u5229\u7528\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u6216\u8005\u8f7b\u91cf\u4e3b\u5e72\u6a21\u578b\u5b9e\u73b0\u52a0\u901f\u3002\u4f46\u662f\u5c0f\u56fe\u50cf\u76f8\u8f83\u4e8e\u539f\u56fe\u50cf\u7f3a\u5931\u4e86\u5f88\u591a\u7a7a\u95f4\u4fe1\u606f\uff0c\u800c\u8f7b\u91cf\u7ea7\u6a21\u578b\u5219\u7531\u4e8e\u88c1\u526a\u901a\u9053\u800c\u635f\u5bb3\u4e86\u7a7a\u95f4\u4fe1\u606f\u3002BiSegNet\u6574\u5408\u4e86Spatial Path (SP) \u548c Context Path (CP)\u5206\u522b\u7528\u6765\u89e3\u51b3\u7a7a\u95f4\u4fe1\u606f\u7f3a\u5931\u548c\u611f\u53d7\u91ce\u7f29\u5c0f\u7684\u95ee\u9898\u3002",date:"2023-12-31T09:31:53.000Z",formattedDate:"2023\u5e7412\u670831\u65e5",tags:[{label:"segmentation",permalink:"/blog/tags/segmentation"},{label:"light-weight",permalink:"/blog/tags/light-weight"}],readingTime:9.905,hasTruncateMarker:!0,authors:[{name:"Gavin Gong",title:"Rubbish CVer | Poor LaTex speaker | Half stack developer | \u952e\u5708\u8eba\u5c38\u7816\u5bb6",url:"https://gong.host",email:"gavin@gong.host",imageURL:"https://github.yuuza.net/visualDust.png",key:"visualdust"}],frontMatter:{title:"BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation",authors:["visualdust"],tags:["segmentation","light-weight"]},prevItem:{title:"Squeeze-and-Excitation Networks",permalink:"/blog/[23]Squeeze-and-Excitation-Networks"},nextItem:{title:"Rethinking BiSeNet For Real-time Semantic Segmentation",permalink:"/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation"}},b={authorsImageUrls:[void 0]},S=[],y={toc:S},w="wrapper";function v(e){var t=e,{components:a}=t,r=f(t,["components"]);return(0,n.kt)(w,u(m(m({},y),r),{components:a,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"BiSeNet\u7684\u76ee\u6807\u662f\u66f4\u5feb\u901f\u7684\u5b9e\u65f6\u8bed\u4e49\u5206\u5272\u3002\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u611f\u53d7\u91ce\u5f88\u96be\u4e24\u5168\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u65f6\u8bed\u4e49\u5206\u5272\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u662f\u5229\u7528\u5c0f\u7684\u8f93\u5165\u56fe\u50cf\u6216\u8005\u8f7b\u91cf\u4e3b\u5e72\u6a21\u578b\u5b9e\u73b0\u52a0\u901f\u3002\u4f46\u662f\u5c0f\u56fe\u50cf\u76f8\u8f83\u4e8e\u539f\u56fe\u50cf\u7f3a\u5931\u4e86\u5f88\u591a\u7a7a\u95f4\u4fe1\u606f\uff0c\u800c\u8f7b\u91cf\u7ea7\u6a21\u578b\u5219\u7531\u4e8e\u88c1\u526a\u901a\u9053\u800c\u635f\u5bb3\u4e86\u7a7a\u95f4\u4fe1\u606f\u3002BiSegNet\u6574\u5408\u4e86Spatial Path (SP) \u548c Context Path (CP)\u5206\u522b\u7528\u6765\u89e3\u51b3\u7a7a\u95f4\u4fe1\u606f\u7f3a\u5931\u548c\u611f\u53d7\u91ce\u7f29\u5c0f\u7684\u95ee\u9898\u3002"),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Semantic segmentation requires both rich spatial information and sizeable receptive field. However, modern approaches usually compromise spatial resolution to achieve real-time inference speed, which leads to poor performance. In this paper, we address this dilemma with a novel Bilateral Segmentation Network (BiSeNet). We first design a Spatial Path with a small stride to preserve the spatial information and generate high-resolution features. Meanwhile, a Context Path with a fast downsampling strategy is employed to obtain sufficient receptive field. On top of the two paths, we introduce a new Feature Fusion Module to combine features efficiently. The proposed architecture makes a right balance between the speed and segmentation performance on Cityscapes, CamVid, and COCO-Stuff datasets. Specifically, for a 2048x1024 input, we achieve 68.4% Mean IOU on the Cityscapes test dataset with speed of 105 FPS on one NVIDIA Titan XP card, which is significantly faster than the existing methods with comparable performance.")),(0,n.kt)("p",null,"\u8bba\u6587\u539f\u6587\uff1a",(0,n.kt)("a",m({parentName:"p"},{href:"https://arxiv.org/abs/1808.00897"}),"BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation"),"\u3002\u9605\u8bfb\u540e\u4f60\u4f1a\u53d1\u73b0\uff0c\u8fd9\u7bc7\u8bba\u6587\u6709\u5f88\u591a\u601d\u8def\u53d7\u5230",(0,n.kt)("a",m({parentName:"p"},{href:"./%5B23%5DSqueeze-and-Excitation-Networks"}),"SENet\uff08Squeeze-and-Excitation Networks\uff09"),"\u7684\u542f\u53d1\u3002"))}v.isMDXComponent=!0}}]);