<!doctype html>
<html lang="zh-cn" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">欢迎来到魔法部日志 | 工具箱的深度学习记事簿</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ml.akasaki.space/blog/[00]unlimited-paper-works"><meta data-rh="true" name="docusaurus_locale" content="zh-cn"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="zh-cn"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="欢迎来到魔法部日志 | 工具箱的深度学习记事簿"><meta data-rh="true" name="description" content="如果你看到了这里，说明你已经准备好开始探求这个领域事物的规律以及这些规律的本源了。作为一个本科生，最适合你入坑的就是开始习惯性阅读领域内论文。大约在我的大二的下半学期，我和我的朋友们开始共同阅读论文并写下笔记。这些笔记粗浅、幼稚，甚至会出现一些理解上的错误——万事开头难。但是我们还是想把这些笔记整理起来——这便是魔法部日志的开始。在我新建文件夹的时候，魔法部日志的文件夹名称是“unlimited paper works”，在成为理性的怀疑者之前，应该先掌握这个科研领域。我们做好了长期投入的准备，并希望把简单的事情做到出人意料得精彩。"><meta data-rh="true" property="og:description" content="如果你看到了这里，说明你已经准备好开始探求这个领域事物的规律以及这些规律的本源了。作为一个本科生，最适合你入坑的就是开始习惯性阅读领域内论文。大约在我的大二的下半学期，我和我的朋友们开始共同阅读论文并写下笔记。这些笔记粗浅、幼稚，甚至会出现一些理解上的错误——万事开头难。但是我们还是想把这些笔记整理起来——这便是魔法部日志的开始。在我新建文件夹的时候，魔法部日志的文件夹名称是“unlimited paper works”，在成为理性的怀疑者之前，应该先掌握这个科研领域。我们做好了长期投入的准备，并希望把简单的事情做到出人意料得精彩。"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-12-31T09:31:53.000Z"><meta data-rh="true" property="article:author" content="https://gong.host"><link data-rh="true" rel="icon" href="/img/logo.svg"><link data-rh="true" rel="canonical" href="https://ml.akasaki.space/blog/[00]unlimited-paper-works"><link data-rh="true" rel="alternate" href="https://ml.akasaki.space/blog/[00]unlimited-paper-works" hreflang="zh-cn"><link data-rh="true" rel="alternate" href="https://ml.akasaki.space/blog/[00]unlimited-paper-works" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="工具箱的深度学习记事簿 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="工具箱的深度学习记事簿 Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.3231e09c.css">
<link rel="preload" href="/assets/js/runtime~main.416d7f00.js" as="script">
<link rel="preload" href="/assets/js/main.d42e6425.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">工具箱的深度学习记事簿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">魔法部日志</a><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">Authors &amp; About</a><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">YetAnotherAkasaki<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="切换浅色/暗黑模式（当前为浅色模式）" aria-label="切换浅色/暗黑模式（当前为浅色模式）" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="最近博文导航"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/[00]unlimited-paper-works">欢迎来到魔法部日志</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder - Classification, Regression and GANs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision - A Survey</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation - Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[06]DeepLab-Series">DeepLab Series</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks - A Survey</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2 - Inverted Residuals and Linear Bottlenecks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN - Fast Semantic Segmentation Network</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets - Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU - Improving Object-Centric Image Segmentation Evaluation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution - Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[19]PointRend-Image-Segmentation-as-Rendering">PointRend - Image Segmentation as Rendering</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[20]Transformer-Attention-is-all-you-need">Transformer - Attention is all you need</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[21]RefineMask-Towards-High-Quality-Instance-Segmentationwith-Fine-Grained_Features">RefineMask - Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet - Low-Light Enhancement Network with Global Awareness</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet - Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[26]CBAM-Convolutional-Block-Attention-Module">CBAM - Convolutional Block Attention Module</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net - Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN - A convolutional neural network for low-light image enhancement</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO - Vision Outlooker for Visual Recognition</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention - Towards High-quality Pixel-wise Regression</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM - A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[36]SOLO-Segmenting-Objects-by-Locations">SOLO - Segmenting Objects by Locations</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT - Real-time Instance Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">CCNet - Criss-Cross Attention for Semantic Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">RepVGG - Making VGG-style ConvNets Great Again</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">PP-LCNet - A Lightweight CPU Convolutional Neural Network</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">Swin Transformer - Hierarchical Vision Transformer using Shifted Windows</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[46]Demystifying-Local-Vision-Transformer">Demystifying Local Vision Transformer</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[47]Discrete-Cosine-Transform-Mask-Representation-for-Instance-Segmentation">DCT-Mask - Discrete Cosine Transform Mask Representation for Instance Segmentation</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[48]Deep-Retinex-Decomposition-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[49]GhostNet-More-Features-from-Cheap-Operations">GhostNet - More Features from Cheap Operations</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[50]Kindling-the-Darkness-A-Practical-Low-light-Image-Enhancer">Kindling the Darkness - A Practical Low-light Image Enhancer</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[51]How-much-Position-Information-Do-Convolutional-Neural-Networks-Encode">How much Position Information Do Convolutional Neural Networks Encode?</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/[52]Axiomatic-Attribution-for-Deep-Networks">Axiomatic Attribution for Deep Networks</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">欢迎来到魔法部日志</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-12-31T09:31:53.000Z" itemprop="datePublished">2023年12月31日</time> · <!-- -->阅读需 40 分钟</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.yuuza.net/visualDust.png" alt="Gavin Gong"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://gong.host" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Gavin Gong</span></a></div><small class="avatar__subtitle" itemprop="description">Rubbish CVer | Poor LaTex speaker | Half stack developer | 键圈躺尸砖家</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>如果你看到了这里，说明你已经准备好开始探求这个领域事物的规律以及这些规律的本源了。作为一个本科生，最适合你入坑的就是开始习惯性阅读领域内论文。大约在我的大二的下半学期，我和我的朋友们开始共同阅读论文并写下笔记。这些笔记粗浅、幼稚，甚至会出现一些理解上的错误——万事开头难。但是我们还是想把这些笔记整理起来——这便是魔法部日志的开始。在我新建文件夹的时候，魔法部日志的文件夹名称是“unlimited paper works”，在成为理性的怀疑者之前，应该先掌握这个科研领域。我们做好了长期投入的准备，并希望把简单的事情做到出人意料得精彩。</p><p>加入魔法部日志也不是什么难事，你只需要热身一下，读完下面的一篇引导，就可以开始了(以下内容已通过语法检查工具<a href="https://github.com/PaperCube" target="_blank" rel="noopener noreferrer">PaperCube</a>的检查)。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-read-and-comprehend-scientific-research-articles">How to Read and Comprehend Scientific Research Articles<a href="#how-to-read-and-comprehend-scientific-research-articles" class="hash-link" aria-label="How to Read and Comprehend Scientific Research Articles的直接链接" title="How to Read and Comprehend Scientific Research Articles的直接链接">​</a></h2><p>Scientific articles are how scholars and researchers communicate with each other. Reading scientific articles helps you to participate in your comprehension by wondering how the researchers explain their ideas. Books, websites, papers, scientific magazines are general places to start with.</p><p>This tutorial will discuss:</p><ul><li>How to read a scientific article</li><li>How to find the main points of an article</li><li>How to take effective notes</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-read-a-scientific-article">How to read a scientific article<a href="#how-to-read-a-scientific-article" class="hash-link" aria-label="How to read a scientific article的直接链接" title="How to read a scientific article的直接链接">​</a></h3><p>The least effective way to read scientific articles is from the start to finish. Instead, expert researchers scan the article skimming for key findings. The structured scientific articles are defined by several distinct sections. Most articles like lab reports are divided into five sections:</p><ul><li>Abstract</li><li>Introduction</li><li>Methods </li><li>Results</li><li>Discussion</li></ul><p>And the most effective way to read a scientific article is to follow this order: Abstract, Discussion, Introduction, Results, Methods. The difference between the original structure and suggested reading order are listed below:</p><table><thead><tr><th>The original structure</th><th>Order suggested</th></tr></thead><tbody><tr><td>Abstract</td><td>Abstract</td></tr><tr><td>Introduction</td><td>Discussion</td></tr><tr><td>Methods</td><td>Introduction</td></tr><tr><td>Results</td><td>Results</td></tr><tr><td>Discussion</td><td>Methods</td></tr></tbody></table><p>By reading in the suggested order, you can quickly find the information you need to determine if the article is useful for you. After you read each section, asking yourself whether the article is interesting and relevant enough to your research assignment will help you to decide whether to continue reading it.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-abstract">The Abstract<a href="#the-abstract" class="hash-link" aria-label="The Abstract的直接链接" title="The Abstract的直接链接">​</a></h4><p>Abstract usually contains four kinds of information:</p><ul><li>Purpose of the study (why they did it)</li><li>Methodology (how they did it)</li><li>Results (what they have found)</li><li>Conclusion (what it means)</li></ul><p>After reading these sections, think about whether you should continue your reading.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-discussion">The Discussion<a href="#the-discussion" class="hash-link" aria-label="The Discussion的直接链接" title="The Discussion的直接链接">​</a></h4><p>This section usually contains things below:</p><ul><li>Clear answers about the question posed in the introduction</li><li>Explanations about how the results supports the conclusions</li></ul><p>After reading this sections ask yourself whether you understand and believe the author(s)&#x27; claims.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-introduction">The Introduction<a href="#the-introduction" class="hash-link" aria-label="The Introduction的直接链接" title="The Introduction的直接链接">​</a></h4><p>The introduction serves two purposes:</p><ul><li>Stimulating and interests the subject</li><li>Putting the article in the large context</li></ul><p>Generally introductions achieve these goals by leading the reader from the <code>General</code>(what is already known to the topic), to the <code>Specific</code>(what is not yet known), to the <code>Focused Question</code>(what the authors are asking). Thus, the authors describe previous works and how they are related to it.</p><p>Before we move on to the next section, ask yourself why the authors did this study, and, does the researched question match up with the conclusions in the discussion?</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-results">The results<a href="#the-results" class="hash-link" aria-label="The results的直接链接" title="The results的直接链接">​</a></h4><p>The results&#x27; section states:</p><ul><li>What the author has found</li><li>Key data, often shown in figures or tables</li></ul><p>Ask yourself if the data collected are appropriate to answer the researched question before moving on to the next section.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-methods">The methods<a href="#the-methods" class="hash-link" aria-label="The methods的直接链接" title="The methods的直接链接">​</a></h4><p>The method sections tells the reader:</p><ul><li>What experiments were done to answer the question stated in the introduction</li></ul><p>This section can be difficult to read for students due to the technical language used and complex details listed. However, you can fully understand what happened by reading it carefully.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-find-the-main-points-of-an-article">How to find the main points of an article<a href="#how-to-find-the-main-points-of-an-article" class="hash-link" aria-label="How to find the main points of an article的直接链接" title="How to find the main points of an article的直接链接">​</a></h3><p>While you are reading the article, also distinguish the author&#x27;s main points. It can be difficult to distinguish between the main point and less relevant sub-points.</p><p>Key places to look for the main points include:</p><ul><li>The article title</li><li>The abstract</li><li>Keywords</li><li>Figure and Table titles</li><li>The first and the last sentences of the Introduction</li></ul><p>The keywords to look out for the main points include:</p><ul><li>&quot;We hypothesize that...&quot;</li><li>&quot;We propose...&quot;</li><li>&quot;We introduce...&quot;</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-take-effective-notes">How to take effective notes<a href="#how-to-take-effective-notes" class="hash-link" aria-label="How to take effective notes的直接链接" title="How to take effective notes的直接链接">​</a></h3><p>Another important part of reading and comprehending a scientific article is to take notes. Effective note-taking will save your time and help you clarify your thoughts.</p><p>Creating a standard template for taking note will help you organize your research and enable you to make quick comparisons and will save your time re-reading articles. </p><p>A possible template of reading articles can be:</p><table><thead><tr><th>Article title</th><th></th></tr></thead><tbody><tr><td>Author(s)</td><td></td></tr><tr><td>Journal</td><td></td></tr><tr><td>Date</td><td></td></tr><tr><td>Pages/Volume</td><td></td></tr><tr><td>Issues</td><td></td></tr><tr><td>URL</td><td></td></tr><tr><td>Main concepts</td><td></td></tr><tr><td>My critical response</td><td></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Summary的直接链接" title="Summary的直接链接">​</a></h3><p>So we know that reading a paper in the proper order, making full understand of the author&#x27;s main points, and taking effective notes can be a effective way to do your research.</p><p>好了，你可以启程了。</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="写作一篇科技类论文">写作一篇科技类论文？<a href="#写作一篇科技类论文" class="hash-link" aria-label="写作一篇科技类论文？的直接链接" title="写作一篇科技类论文？的直接链接">​</a></h2><p>注：这一部分是在听了陈关荣教授的分享后写下的。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="认真写作的重要性">认真写作的重要性<a href="#认真写作的重要性" class="hash-link" aria-label="认真写作的重要性的直接链接" title="认真写作的重要性的直接链接">​</a></h3><p>请认真写作。</p><p><img loading="lazy" alt="image-20210607125125488" src="/assets/images/image-20210607125125488-86c07af5a52352c25403fffc125de73d.png" width="1063" height="586" class="img_ev3q"></p><p>上图是不认真写作的结果。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="一篇科技论文典型的结构">一篇科技论文典型的结构<a href="#一篇科技论文典型的结构" class="hash-link" aria-label="一篇科技论文典型的结构的直接链接" title="一篇科技论文典型的结构的直接链接">​</a></h3><table><thead><tr><th>Content</th><th>描述</th></tr></thead><tbody><tr><td>Title（题目）</td><td>文献的题目。通常情况下，文献的题目应该简单、准确、精炼、引人注目，表达文章主要内容或思想。</td></tr><tr><td>Author（作者）</td><td>文献的作者。（千万不能未经同意和许可就随便地把别人例如导师的名字加到文章上单方面去投稿）</td></tr><tr><td>Abstract（摘要）</td><td>文献的摘要，要全面准确、简明握要。摘要是供出版社、图书馆、信息库检索用的，通常要单独刊登，因此，要自我完备，尽量不要使用数学公式、数学符号、方程序号、 引文序号、图表等等。</td></tr><tr><td>Keywords（关键词）</td><td>文章的关键字，文章所包含的研究领域或方向，并且应该用单数（例如：“attractor” 而不是 “attractors”）。SCI 系统利用关键词来分类文献，并且读者利用关键词来搜索文章。 关键词不全面可能导致检索遗漏和引用减少。</td></tr><tr><td>Introduction（引言）</td><td>引言应该全面、客观、准确地介绍问题的背景和历史发展， 他人以及自己的贡献，本文的动因和主要成果。注意，短文在引言部分并不一定需要说明文章的基本结构。</td></tr><tr><td>Sections（段落）</td><td>文章的内容分为很多段落。这些段落的标题、编号和格式应该尽量统一；在写作时，要尽量避免冗长的句子、避免不必要的符号和定义、避免太多太滥的缩写、避免太多太滥的方程号码。</td></tr><tr><td>Conclusion（结论）</td><td>文章的结论。结论中不要简单地改写甚至重复文章的摘要；和摘要部分一样，结论部分不要援引前文中出现过的方程号码、图表号码， 不要重新讨论数学公式、给出定理补充证明之类。</td></tr><tr><td>Acknowledgement（致谢）</td><td>在这部分可以感谢认真而又有实质性建议的匿名审稿人、认真而又有实质性建议的朋友、以及有关科研基金。</td></tr><tr><td>References（参考文献）</td><td>这部分列表呈现写作时参考的文献。请注意严格使用标准格式。关于格式，请使用统一格式，或使用你打算投稿的那个杂志的格式。文献的多少要恰当：不要漏掉重要和必要的文献，又不要罗列多余且毫不相关的文章。</td></tr><tr><td>Appendix（附录）</td><td>附录通常可以放一些比较长的引理和定理的证明，方便读者在阅读简洁的原文后查阅。</td></tr></tbody></table><p>你可以通过一些工具来规范你的写作。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="abstract的写作技巧">Abstract的写作技巧<a href="#abstract的写作技巧" class="hash-link" aria-label="Abstract的写作技巧的直接链接" title="Abstract的写作技巧的直接链接">​</a></h3><p>以下内容摘抄自网络：</p><blockquote><p>套路一般是，先说大环境下本领域的发展，分类，极其对其他领域的作用。进而转到其中某某模块(你针对的模块)对整体的性能至关重要。该模块已被多个其他领域应用，如U,V,W(列出参考文献)。针对该模块，大家都使用的方法是Z，近十年来一直如此。后续针对传统方法Z的不足，近几年有学者提出了D方法(ECCV2017)，用以改善XXXX。接着针对D方法的不足，又有人提出了E，解决了D的问题，比如提高D的速度，或者D的稳定性，或者是D的推广版本。E是相当经典的，这么多年以来成为了主导，可谓人尽皆知。最新的研究进展中，有学者还提出了F, H等变体，分别考虑了XXXX，有的还应用在其他领域中。但是(关键来了)，上述这些方法，都仅仅考虑了XXXX层面，因素。However, we observed that......，they may suffer from……，they face the problem of……这个地方最好需要你用一句神来之笔的观点说出这些方法的问题，从而让人眼前一亮，让人恍悟好像这些方法确实是这么一回事，甚至让人恍悟原来E方法能有提升是出于背后这么个原因。总之你若能总结到类似于这样的深刻道理，那基本上审稿人对你论文的看法就是very novel。加之你的提升有1.5个点这么多，那么审稿人对你实验结果的看法也将是significant或very convincing。</p></blockquote><ul><li>为了流畅地书写Abstract，你需要有足够的文献储备，这样才能做到信手拈来。</li><li>注意语言表达要客观，要尊重，还要犀利。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="论文的投稿流程">论文的投稿流程<a href="#论文的投稿流程" class="hash-link" aria-label="论文的投稿流程的直接链接" title="论文的投稿流程的直接链接">​</a></h3><ul><li>Have an idea （你有一个想法）</li><li>Do your research （完成你的研究和实验）</li><li>Write your paper （进行论文写作）</li><li>Identify  a journal （选择要发表的期刊。老手的一些想法是有想法之后先选择期刊再进行论文写作，有许多直接被拒的论文不是写的不好而是找错了地方。）</li><li>Submit your paper （提交你的论文）</li><li>Receive reviewers&#x27; comments （收到审稿人评价）</li><li>Revise and submit （修改后重新提交）</li><li>Receive further comments （收到后续审稿意见）</li><li>Revise and submit （修改后重新提交）</li><li>......</li><li>Get accepted and published （被接受并发表）</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="论文的审稿流程">论文的审稿流程<a href="#论文的审稿流程" class="hash-link" aria-label="论文的审稿流程的直接链接" title="论文的审稿流程的直接链接">​</a></h3><ul><li>Editor-in-Chief receives manuscript （主编收到论文）</li><li>Checks for quality, scope （检查论文质量。Desk rejection 也就是拒稿往往是在这一步发生的）</li><li>Assigns to an editor including the EIC herself （分配给编辑审阅）</li><li>Handling editor invites reviewers （编辑邀请审稿人）</li><li>May or may not use suggested reviewers （接受或者不接受该审稿人评阅）</li><li>Receives reviewers&#x27; comments （收到审稿人意见）</li><li>Makes decision : Reject, major revision, minor revision or accept （做决定：拒绝，重大修改，轻微修改，还是接受论文）</li><li>reject and resubmit （拒绝并重新提交）</li><li>Receives revised manuscript （接收修改后的论文）</li><li>Invites reviewers （邀请评阅）</li><li>Likely the previous reviewers, but could also be new reviewers （可能是之前的审稿人，也可能是新的审稿人）</li><li>Receives reviewers&#x27; comments （收到审稿人意见）</li><li>......</li><li>Accepts （接受）</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="常见的简单审稿意见在写作期就可以避免">常见的简单审稿意见（在写作期就可以避免）<a href="#常见的简单审稿意见在写作期就可以避免" class="hash-link" aria-label="常见的简单审稿意见（在写作期就可以避免）的直接链接" title="常见的简单审稿意见（在写作期就可以避免）的直接链接">​</a></h3><table><thead><tr><th align="center">审稿意见</th><th align="left">审稿意见全文</th><th align="left">参考中文</th><th align="left">举例</th></tr></thead><tbody><tr><td align="center">参考文献不要扎堆</td><td align="left">Eliminate multiple references. After that please check the manuscript thoroughly and eliminate all the lumps in the manuscript. This should be done by characterizing each reference individually. This can be done by mentioning 1 or 2 phrases per reference to show how it is different from the others and why it deserves mentioning</td><td align="left">消除出现在同个位置的多个引用。在那之后，请彻底检查手稿，消除所有的扎堆文献。这应该通过单独描述每个引用来实现。这可以通过在每次引用中提到1或2个短语来说明它与其他的不同之处，以及为什么它值得提到。</td><td align="left">修改如“前人的工作有<!-- -->[<!-- -->1<!-- -->]<!-- -->[<!-- -->2<!-- -->]<!-- -->[<!-- -->3<!-- -->]<!-- -->[<!-- -->4<!-- -->]<!-- -->[<!-- -->5<!-- -->]<!-- -->[<!-- -->6<!-- -->]<!-- -->[<!-- -->7<!-- -->]<!-- -->”的大量引用，仅保留必要的。</td></tr><tr><td align="center">结论中增加意义量化及对比</td><td align="left">In the conclusions, in addition to summarizing the actions taken and results, please strengthen the explanation of their significance. It is recommended to use quantitative reasoning comparing with appropriate benchmarks, especially those stemming from previous work.</td><td align="left">在结论中，除了总结所采取的行动和结果外，请加强对其重要性的解释。建议使用定量推理与适当的基准进行比较，特别是那些源于以前工作的基准。</td><td align="left">增加如“我们在前人提出的xxx之上又做出了怎样的贡献”的语句。</td></tr><tr><td align="center">结论中增加意义量化及对比</td><td align="left">Please revise the conclusion in paragraphs. Conclusions are not just about summarizing the key results of the study, it should highlights the insights and the applicability of your findings/results for further work. Please make it more concise and show only the high impact outcomes. Report your Conclusions in one or maximum 2 paragraph. Avoid <a href="https://en.wikipedia.org/wiki/Bullet_(typography)" target="_blank" rel="noopener noreferrer">bullet form</a>).</td><td align="left">请在段落中修改结论。结论不仅仅是总结研究的关键结果，它应该突出你的发现结果对进一步工作的洞察力和适用性。请让它更简洁，只显示高影响的结果。一段或最多两段报告你的结论。避免<a href="https://en.wikipedia.org/wiki/Bullet_(typography)" target="_blank" rel="noopener noreferrer">子弹形式</a>。</td><td align="left">一般结论不超过半页纸。请不要在结论里使用分条分点的段落形式。</td></tr><tr><td align="center">删除多余的虚词</td><td align="left">Eliminate the use of redundant words, e.g. in this way, recently, respectively, therefore, currently, thus, hence, finally, to do this, first, in order, however, moreover, nowadays, consequently, in addition, additionally, furthermore. Revise all similar cases, as removing these term(s) would not significantly affect the meaning of the sentence.</td><td align="left">消除多余虚词的使用，例如：这样做、最近、分别、目前、因为、因此，最后、这件事、首先、顺序、然而、此外、如今、因此、此外等词汇。修改或删除这些“删除后不会对句子的意思产生重大影响”的词。</td><td align="left">删除诸如“关于这件事...”等无关语义的连接，对各种虚词的使用仅保留必要的部分。</td></tr><tr><td align="center">对一千以上的数字增加分隔符</td><td align="left">Add a separator for the numbers over 1,000. Check all numbers including those in the tables/figures.</td><td align="left">为超过1000的数字添加分隔符。检查所有数字包括表/图中的数字。</td><td align="left">例如将“1000”改为“1,000”。</td></tr><tr><td align="center">检查下标格式</td><td align="left">Check all format, e.g. &quot;SO2&quot; in Fig.5, 2 should be in subscript, check all。</td><td align="left">在Fig.5中，2应该是下标，请检查全部格式。</td><td align="left">例如二氧化硫<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><msub><mi>O</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">SO_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>不小心写成了<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>O</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">SO2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">SO</span><span class="mord">2</span></span></span></span></span>，请检查并改正。</td></tr><tr><td align="center">请使用国际制单位</td><td align="left">Please use SI unit. E,g, m instead of meter, t instead of tons. d instead of day, y instead of years or yr, h instead of hours, M instead of million, kg instead of kilogram or Kg (including those in figures/tables) and leave a space between the value and unit. Please check all.</td><td align="left">请使用国际制单位。例如，“m”代替米，用“t”代替吨。用“d”代替“天”，用“y”代替“年”用“h”代替“小时”用“M”代替“百万”，用“kg”代替“公斤”或“Kg”(包括图表中的单位)，并在数值和单位之间留一个空格。</td><td align="left">原文中已经足够举例。</td></tr><tr><td align="center">没有添加页码或行号</td><td align="left">I suggest the authors add page and line numbers when they re-submit it. It will be easier for reviewers to make comments.</td><td align="left">我建议作者在重新提交时添加页码和行号。评审者可以更容易地发表评论。</td><td align="left">加上页码，需要行号的位置增加行号。</td></tr><tr><td align="center">图表缺少摘要</td><td align="left">Please provide a graphical abstracts.</td><td align="left">请提供图表摘要。</td><td align="left">一张没有任何文字描述的图表。</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="常见的复杂审稿意见">常见的复杂审稿意见<a href="#常见的复杂审稿意见" class="hash-link" aria-label="常见的复杂审稿意见的直接链接" title="常见的复杂审稿意见的直接链接">​</a></h3><table><thead><tr><th align="center">审稿意见</th><th>审稿意见全文</th><th>参考中文</th></tr></thead><tbody><tr><td align="center">文章亮点问题</td><td>This is not a highlight of the research.</td><td>这不是研究的重点。</td></tr><tr><td align="center">文章缺少亮点</td><td>I think highlights are mandatory for this journal, and they are missing in this paper.</td><td>我认为本期刊论文必须具备Highlight的部分，但是这篇论文中没有</td></tr><tr><td align="center">文章类型比较像报告而不是论文</td><td>On the whole, the manuscript is more like a thesis or a report rather than a scientific research. In my understanding, this is not acceptable in a scientific paper of this field of knowledge. The paper is well-written and organized. However, it seems more a technical report than a scientific contribution at this moment. I&#x27;m not sure about the SCIENTIFIC CONTRIBUTION of this paper, since most of the results and discussions seems to be more TECHNICAL than SCIENTIFIC.</td><td>总的来说，稿件更像是理论或报告，而不是科学研究。(这种形 式)在这一知识领域的学术论文中是不能接受的。这篇论文写得很好，条理清晰。然而，目前看来，它更像是一份技术报告，而不是一份学术成果。我不确定这篇论文的学术贡献，因为大多数结果和讨论似乎缺乏学术性。</td></tr><tr><td align="center">文章类型比较像报告而不是论文</td><td>This existing review article makes few relevant contributions to the academic environment. The whole article looks like a technical report, rather than a scientific one. Please tell readers, what the research gaps are, what the scientific contributions are. Then, pls. re-organize the text.</td><td>现有的综述文章对学术环境的相关贡献很少。整篇文章看起来像是一篇技术报告，而不是学术论文。请告诉读者(这一领域的)研究空白是什么，科学贡献是什么，并重新组织文章。</td></tr><tr><td align="center">文章新颖性不足</td><td>My first and primary concern lies in the novelty of this work, as <!-- -->|<!-- -->feel that the novelty issue has not been sufficiently.</td><td>我首先关注的是这个作品的新颖性，因为我觉得这个新颖性问题在目前的版本中没有得到充分的强调。应该回答一个重要的问题:这项工作是否填补了一些以前的文章不能解决的知识空白？</td></tr><tr><td align="center">论文价值体现不足</td><td>The author needs to provide the contributions of this study more specific.</td><td>作者需要更具体地提供本研究的贡献。</td></tr><tr><td align="center">没有体现研究的重要性</td><td>The second major concern is related to the significance of this work, that is, how the results derived from the work be benefitting to the WEEE management? A list of issues can be proposed.</td><td>第二个主要的关注点与这项工作的意义有关，即这项工作的结果如何有益于WEEE管理可以提出一系列问题。</td></tr><tr><td align="center">没有体现研究的重要性</td><td>The discussion is related to the theory, but the relevance of the findings to the modernization of the state of art is not clear. The : methodology is well designed, but there are missing elements that relate the proposed to what was actually found by the authors. Contributions are unclear.</td><td>讨论与理论有关，但研究结果与当前（研究的）技术方法水平的相关性并不清楚。该方法设计得很好，但是缺少一些与作者实际发现的内。容相关的元素。贡献尚不清楚。</td></tr><tr><td align="center">摘要需要重新写</td><td>The format of the abstract is not correct. Please read the author guidelines. Is too descriptive and lengthy. Please add some quantities to it and shorten it through focusing on the main point.</td><td>摘要的格式不正确。请阅读作者指南。太描述性和冗长。请增加一些定量描述，并通过主要观点来缩减摘要内容。</td></tr><tr><td align="center">摘要需要重新写</td><td>|<!-- --> suggest the authors to rewrite the abstract with a focus on background, objectives, methodology, main findings and conclusion. Please add a sentence which shows the necessity of the study.</td><td>我建议作者重写摘要，重点关注背景、目标、方法、主要发现和结论。请说明研究的必要性。</td></tr><tr><td align="center">引言有些跑题</td><td>Actually, it is a little far from the topic of this study. Literature review - this section is quite extensive in its coverage, but tends to summarize disaggregate studies of EV adoption derived from surveys. The research has seemingly overlooked the existing literature which applies spatial models to EV registrations, which is surprising given that this is the focus of the work. I&#x27;d advise the authors to examine the following papers as they <!-- -->[a]<!-- --> might find them useful for results comparisons and <!-- -->[b]<!-- --> demonstrate that the association between EV registrations and charge point availability has been considered.</td><td>事实上，这离本研究的主题有些偏离。文献综述-本节涵盖范围相当广泛，但倾向于总结从调查中得出的采用电动汽车的研究令人惊讶的是，这项研究似乎忽略了（总结）将空间模型应用于电动汽车登记的现有文献，因为这是工作的重点。我建议作者们检查一下下面的论文，因为他们<!-- -->[a]<!-- -->可能会发现它们有利于结果对比，并且<!-- -->[b]<!-- -->证明了电动汽车注册和充电桩可用性之间的关联。</td></tr><tr><td align="center">引言思路不清晰</td><td>I do not think the authors make it very clear of their contributions to this field.</td><td>我认为作者没有很清楚地对他们在这个领域的贡献进行说明。</td></tr><tr><td align="center">引言思路不清晰</td><td>In the &quot;Introduction&quot; and &quot;Literature review&quot; section, I do not think the authors make it very clear of their contributions to this field. They have citied almost 90 papers about the relevant studies at the city scale, which is quite a lot. But it is still not clear to me, what specific research questions the authors are asking and how they contribute to the existing studies.</td><td>在“介绍”和“文献综述”部分，我认为作者并没有很清楚地说明他们对这个领域的贡献。他们引用了近90篇城市尺度的相关研究论文，数量相当可观。但我仍然不清楚，作者研究了哪些具体的问题，以及他们有何贡献。</td></tr><tr><td align="center">研究方法介绍不够</td><td>Methodology - the preliminary focus groups are an interesting component to the work, but are not outlined in sufficient detail. l&#x27;d advise that more clarity is offered concerning <!-- -->[a]<!-- --> who participated, <!-- -->[b]<!-- --> how the narratives were analyzed, <!-- -->[c]<!-- --> the main findings.</td><td>方法-初步的焦点小组是工作中的重要的组成部分，但没有(对此)给出充分的描述。我建议，应该就<!-- -->[a]<!-- -->参与的人，<!-- -->[b]<!-- -->如何分析的，<!-- -->[c]<!-- -->主要发现，进行更清晰的说明。</td></tr><tr><td align="center">应用对象新但方法旧</td><td>While this is the first application in XXXX, such an approach has been utilized in the past.</td><td>虽然这是在XXXX领域的第一次应用，但这种方法在过去也被使用过。</td></tr><tr><td align="center">缺乏对比</td><td>The author should provide the advantages of this paper compared to other types of works.</td><td>作者应该提供这篇论文相较于其他工作的优点。</td></tr><tr><td align="center">讨论不够深入</td><td>I read the results and discussion section completely. The discussion section is the main part of a paper, but this manuscript mainly reported the data of the modelling without discussing it through adding available reasoning for justifying the result. I recommend author adding several reasoning and comparison through available publications in the literature.</td><td>我完整地阅读了结果和讨论部分。讨论部分是论文的主要部分，但这篇稿件主要描述了模型的数据，并没有通过增加可用的推理来对结果进行讨论。我建议作者在结合文献的基础上添加一些推理和比较。</td></tr><tr><td align="center">讨论部分建议不够详细</td><td>Please discuss qualitatively and quantitatively for &quot;Suggestions for further improvements&quot; in detail.</td><td>请就“进一步改进的建议”进行详细的定性和定量讨论。</td></tr><tr><td align="center">讨论部分缺乏启示意义</td><td>Please insert a section on the implications of the study. Who benefits with it? What problem can the study help to solve? What&#x27; s next?</td><td>请插入一个部分讨论该研究的影响。谁从中受益了?这项研究可以帮助解决什么问题?下一步是什么?</td></tr><tr><td align="center">结论需要精炼</td><td>The conclusion part should be more refined to make the findings and contributions of the paper clearer. Furthermore, please note the difference between the conclusions and abstract.</td><td>结论部分应该更加精炼，使论文的发现和贡献更加清晰。此外，请注意结论和摘要之间的区别。</td></tr><tr><td align="center">结论需要精炼</td><td>I believe that this result can be obtained without too much analysis. As an alternative, it is recommended to use quantitative reasoning comparing with appropriate benchmarks.</td><td>我相信这个结果不需要太多的分析就可以得到。作为一-种替代方法，建议使用定量推理与适当的基准进行比较。</td></tr><tr><td align="center">文章贡献不够明确</td><td>So a clearer illustration of contribution or innovation should be further provided in the introduction and conclusion.</td><td>因此在引言和结论中应该进一步提供一个更清晰的贡献或创新的说明。</td></tr><tr><td align="center">语言使用需要修缮</td><td>The presentation should be further improved by native speakers, especially for those grammatical errors, typographical errors, and bad structured sentences.</td><td>文献应该由母语者进一步改进，特别是那些语法错误、排版错误、句子结构有问题的地方。</td></tr></tbody></table><h1>修改原稿</h1><p>Submit the original manuscript showing clearly all textual changes using track changes. Just highlighting textual changes in yellow (or other color) is not acceptable. This includes all edits related to reviewer(s) comments and the Editorial points. Do also submit the clean revised version of the manuscript.</p><p>请使用修订模式修改原稿，或使用其他颜色标注修改的部分。也请提交一份干净的完全修改版。</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="qa">Q&amp;A<a href="#qa" class="hash-link" aria-label="Q&amp;A的直接链接" title="Q&amp;A的直接链接">​</a></h2><ol><li><p>Q：为什么每篇笔记后面首先会跟一个笔记作者的信息的三级标题？</p><p>A：为了建立静态索引。这样你在搜索框里就能直接通过搜索笔记作者的名称来找到他/她写下的全部笔记。这样做只是临时的，新的办法还没有找到。</p></li><li><p>Q：为什么笔记的格式不统一？</p><p>A：因为本部分是又很多人一起写下的笔记。大家写笔记的风格都不一样。</p><p>Q：那怎样读到适合自己的笔记格式？</p><p>A：如果你更倾向于阅读某位笔记作者的笔记，可以在网页右上方的搜索框搜索其名称。</p></li><li><p>Q：这些笔记的排列有什么顺序吗？</p><p>A：有，时间顺序。越新的笔记越靠下。将来unlimited-paper-works将会从ml.akasaki.space迁移出去，到时候会使用更合理的排列顺序。</p></li><li><p>Q：读了这些笔记就一定懂了这些论文吗？</p><p>A：并不。有机会请阅读原论文。这些笔记并不保证完善，甚至可能出现错误。</p></li></ol><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="随时会变的没什么用的内容">随时会变的没什么用的内容<a href="#随时会变的没什么用的内容" class="hash-link" aria-label="随时会变的没什么用的内容的直接链接" title="随时会变的没什么用的内容的直接链接">​</a></h2><p>这次的没什么用内容是我学习的过程中遇到一些困惑，以及我的牢骚。简述之就是：才疏学浅，领域又发展太快，感觉出现了泡沫，找不到方向。</p><blockquote><p>现在越看越觉得除了那些创新backbone的论文，其他这些论文新技术天天出，但是都感觉在哪似曾相识（似乎就是以前看过的哪几个论文东拼西凑一下），看完了感觉似乎自己也能想出来（但其实完全想不出来），论文效果似乎很好，结果跑了发现完全跑不到，等差不多快跑到了新技术又出了。</p></blockquote><p>我最近主要的学习方向是使用深度学习(deep learning)技术的计算机视觉(CV, computer vision)分割(segmentation)任务。可能是因为深度学习技术发展的太快了，尤其是卷积神经网络(CNN, convolutional neural network)之后，一直到不久前GAN(generative adversarial network)开始流行于各个任务，仅仅花了不到十年。</p><p>在<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+Y" target="_blank" rel="noopener noreferrer">Yizeng Han</a>等的综述论文<a href="/blog/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks: A Survey</a>中，作者将视觉领域的神经网络近十年的发展分为这样几个阶段：</p><ol><li><p>快速发展阶段（Fast developing stage），2012~2015</p><p>神经网络的设计变得多样化，出现了包括AlexNet、VGG、GoogLeNet在内的一系列代表性网络结构。</p></li><li><p>发展成熟阶段（Mature stage），2015~2017</p><p>这个阶段出现了很多至今都起到了很重要的影响的或是依然被大家经常使用的网络结构，例如ResNet、DenseNet等</p></li><li><p>繁荣发展阶段（Properous stage），2017~Now</p><p>人们设计了很多多样化的效果优秀的神经网络，并且大量出现了很多新型的神经网络，例如轻量级网络CondenseNet、ShuffleNet，利用自动搜索技术设计的模型NASNet、DARTS，还有这篇论文想要介绍的动态神经网络MSDNet、Block-Drop、Glance and Focus等，以及突然就火起来的Transformer。</p></li></ol><p>在之前几十年的AI发展中，大部分时候图像处理走的都很慢。但是在当前阶段，想要再做哪怕一点点improvement都很难。</p><p>一些开创性的工作比如<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioffe%2C+S" target="_blank" rel="noopener noreferrer">Sergey Ioffe</a>等人的<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener noreferrer">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>，或是一些非线性的激活函数，或是<a href="http://yann.lecun.com/" target="_blank" rel="noopener noreferrer">Yann LeCun</a>等人在<a href="/ch2p2/[1]LeNet">Gradient-Based Learning Applied to Document Recognition</a>（LeNet）中第一次使用卷积神经网络进行手写数字识别，这些工作都要去从数学那一块找新东西，这些方法有的以前可能只在理论上出现过，并且难以被理解或证明有效性，投入实验后也不一定能work，上述这些工作通过实验证明了其有效性，后人就开始在其基础上开展工作了。很遗憾的是这些一旦出现就会产生巨大影响的工作不会经常出现。</p><p>很多对后人具有重要且深远影响的工作例如<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Simonyan%2C+K" target="_blank" rel="noopener noreferrer">Karen Simonyan</a>等人的<a href="/ch2p2/[7]VGGNet">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>（深度卷积网络的初步探索）以及<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K" target="_blank" rel="noopener noreferrer">Kaiming He</a>等人的<a href="/ch2p2/[11]ResNet">Deep Residual Learning for Image Recognition</a>（首次提出残差网络结构）都具有巨大的创新：比如使用了全新的网络结构，或是全新的目标函数（loss function, 或称为损失函数），或者很新的正则化（regularizer）方法。最近也有一些具有重大影响的新结构，例如<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani%2C+A" target="_blank" rel="noopener noreferrer">Ashish Vaswani</a>等人的<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Attention Is All You Need</a>也就是Transformer中，结合了最新的神经网络注意力(Attention)机制，抛弃了的CNN和RNN结构，整个网络结构完全是由Attention机制组成。这些方法往往需要大量的积累和实验，不可能经常做出。</p><p>最新的工作它们之间往往具有很大的相关性，即便它们出自不同的作者。例如，<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+C" target="_blank" rel="noopener noreferrer">Changqian Yu</a>等人的论文<a href="/blog/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a>中，有许多思想参考了<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+J" target="_blank" rel="noopener noreferrer">Jie Hu</a>等人的<a href="/blog/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks</a>。根据某项创新，可能会出现更多类似的创新，应用于同领域会应用于其他领域。这类工作的出现速度非常之快：研究者在阅读前人工作时发现不做或可以修改的点，就会进行实验并迅速发出一篇论文。在结果中，研究者往往会注明新的研究达到了多高的精度，有时还会附赠一份源代码。但是其他人尝试这份源代码时，却发现精度远远达不到论文中提及的水平。实际上，模型的表现不确定因素实在是太多。</p><p>就中国人的数量来说，如果每个研究生都要水出一篇论文，可能会导致领域内论文平均质量的下降。这个领域再也回不到每篇论文都具有很大创新和影响的时代了。</p><blockquote><p>有研究者网友打趣地说：计算机视觉方面的论文可以分为以下几类：「只想浑个文凭」、「教电脑生成更多猫的照片」、「ImageNet上试验结果精度提升0.1%」、「手里有很棒的数据集但并不打算公开」、「3年过去了，代码还在赶来的路上」、「实验证明还是老的baseline更好」、「我们的数据集更大」、「花钱越多，效果越好」...</p></blockquote><p>本人是一个名不见经传大学的本科生，既没有卓越的能力，也没有远见的眼光。想研究一个方向，只能摸索着来。也许有的时候努力方向是错的，但是完全不能自知。可以阅读的文献是大量的，但其中包含的有用的信息总量却不高。对于当前这个方向会怎样继续发展、应该从哪里着手创新，既没有神明现身说法，也是才疏学浅的我所不能自己知晓的——这种具有独特风味的难受也许只有菜鸡才能深有体会吧。</p><p>等一位贵人点醒无知的我。我的邮箱：<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>i</mi><mi>y</mi><mi>a</mi><mi mathvariant="normal">@</mi><mi>a</mi><mi>k</mi><mi>a</mi><mi>s</mi><mi>a</mi><mi>k</mi><mi>i</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>p</mi><mi>a</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">miya@akasaki.space</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">mi</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord mathnormal">a</span><span class="mord">@</span><span class="mord mathnormal">aka</span><span class="mord mathnormal">s</span><span class="mord mathnormal">aki</span><span class="mord">.</span><span class="mord mathnormal">s</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal">ce</span></span></span></span></span>。</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col margin-top--sm"><a href="https://github.dev/neet-cv/ml.akasaki.space/blob/master/blog/[00]unlimited-paper-works.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="博文分页导航"><a class="pagination-nav__link pagination-nav__link--next" href="/blog/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs"><div class="pagination-nav__sublabel">较旧一篇</div><div class="pagination-nav__label">The Devil is in the Decoder - Classification, Regression and GANs</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#how-to-read-and-comprehend-scientific-research-articles" class="table-of-contents__link toc-highlight">How to Read and Comprehend Scientific Research Articles</a><ul><li><a href="#how-to-read-a-scientific-article" class="table-of-contents__link toc-highlight">How to read a scientific article</a></li><li><a href="#how-to-find-the-main-points-of-an-article" class="table-of-contents__link toc-highlight">How to find the main points of an article</a></li><li><a href="#how-to-take-effective-notes" class="table-of-contents__link toc-highlight">How to take effective notes</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></li><li><a href="#写作一篇科技类论文" class="table-of-contents__link toc-highlight">写作一篇科技类论文？</a><ul><li><a href="#认真写作的重要性" class="table-of-contents__link toc-highlight">认真写作的重要性</a></li><li><a href="#一篇科技论文典型的结构" class="table-of-contents__link toc-highlight">一篇科技论文典型的结构</a></li><li><a href="#abstract的写作技巧" class="table-of-contents__link toc-highlight">Abstract的写作技巧</a></li><li><a href="#论文的投稿流程" class="table-of-contents__link toc-highlight">论文的投稿流程</a></li><li><a href="#论文的审稿流程" class="table-of-contents__link toc-highlight">论文的审稿流程</a></li><li><a href="#常见的简单审稿意见在写作期就可以避免" class="table-of-contents__link toc-highlight">常见的简单审稿意见（在写作期就可以避免）</a></li><li><a href="#常见的复杂审稿意见" class="table-of-contents__link toc-highlight">常见的复杂审稿意见</a></li></ul></li><li><a href="#qa" class="table-of-contents__link toc-highlight">Q&amp;A</a></li><li><a href="#随时会变的没什么用的内容" class="table-of-contents__link toc-highlight">随时会变的没什么用的内容</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">鲁ICP备2021025239号-2 Copyright © 2023 neet-cv.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.416d7f00.js"></script>
<script src="/assets/js/main.d42e6425.js"></script>
</body>
</html>